<!DOCTYPE html>
<html>
<head>

  <title>0.2 Enter Fibonacci</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0/katex.min.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0/katex.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0/contrib/auto-render.min.js"></script>

  <link href="../github-markdown.css" rel="stylesheet" type="text/css"/>
  <style>
      .markdown-body {
          box-sizing: border-box;
          min-width: 200px;
          max-width: 980px;
          margin: 0 auto;
          padding: 45px;
      }

      @media (max-width: 767px) {
          .markdown-body {
              padding: 15px;
          }
      }
  </style>
  <link rel="stylesheet" href="../highlight/styles/atom-one-light.css">

  <script src="../highlight/highlight.pack.js"></script>
  <script>hljs.initHighlightingOnLoad();</script>

</head>
<body class="markdown-body">

  <h2 id="enter-fibonacci">0.2 Enter Fibonacci</h2>
  <p>Al Khwarizmi's work could not have gained a foothold in the West were it not for the efforts of one man: the 15th century Italian mathematician <a href="https://en.wikipedia.org/wiki/Fibonacci">Leonardo Fibonacci</a>, who saw the potential of the positional system and worked hard to develop it further and propagandize it.</p>
  <p>But today Fibonacci is most widely known for his famous sequence of numbers</p>
  <p><span class="math display">\[
  0, 1, 1, 2, 3, 5, 8, 13, 21, 34, \cdots,
  \]</span></p>
  <p>each the sum of its two immediate predecessors.</p>
  <p>More formally, the Fibonacci numbers <span class="math inline">\(F_n\)</span> are generated by the simple rule</p>
  <p><span class="math display">\[
  F_n =
  \begin{cases}
  F_{n-1} + F_{n-2} &amp; \text{if}\ n &gt; 1 \\
  1 &amp;\text{if}\ n = 1 \\
  0 &amp;\text{if}\ n= 0
  \end{cases}
  \]</span></p>
  <p>No other sequence of numbers has been studied as extensively, or applied to more fields: biology, demography, art, architecture, music, to name just a few. And, together with the powers of <span class="math inline">\(2\)</span>, it is computer science's favorite sequence.</p>
  <p>In fact, the Fibonacci numbers grow <em>almost</em> as fast as the powers of <span class="math inline">\(2\)</span>: for example, <span class="math inline">\(F_{30}\)</span> is over a million, and <span class="math inline">\(F_{100}\)</span> is already 21 digits long! In general, <span class="math inline">\(F_{n} \approx 2^{0.694n}\)</span> (see Exercise 0.3). But what is the precise value of <span class="math inline">\(F_{100}\)</span>, or of <span class="math inline">\(F_{200}\)</span>?</p>
  <p>Fibonacci himself would surely have wanted to know such things. To answer, we need an algorithm for computing the <span class="math inline">\(n\)</span>th Fibonacci number.</p>
  <h3 id="an-exponential-algorithm">An exponential algorithm</h3>
  <p>One idea is to slavishly implement the recursive definition of <span class="math inline">\(F_{n}\)</span>. Here is the resulting algorithm, in the pseudocode notation used throughout this book:</p>
  <div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="kw">def</span> fib1(n):
          <span class="cf">if</span> n <span class="op">==</span> <span class="dv">0</span>:
                  <span class="cf">return</span> <span class="dv">0</span>
          <span class="cf">if</span> n <span class="op">==</span> <span class="dv">1</span>:
                  <span class="cf">return</span> <span class="dv">1</span>
          <span class="cf">return</span> fib1(n <span class="op">-</span> <span class="dv">1</span>) <span class="op">+</span> fib1(n <span class="op">-</span> <span class="dv">2</span>)</code></pre></div>
  <p>Whenever we have an algorithm, there are three questions we always ask about it:</p>
  <ol style="list-style-type: decimal">
  <li><p>Is it correct?</p></li>
  <li><p>How much time does it take, as a function of <span class="math inline">\(n\)</span>?</p></li>
  <li><p>And can we do better?</p></li>
  </ol>
  <p>The first question is moot here, as this algorithm is precisely Fibonacci's definition of <span class="math inline">\(F_n\)</span>. But the second demands an answer. Let <span class="math inline">\(T(n)\)</span> be the number of computer steps needed to compute <span class="math inline">\(\text{fib1}(n)\)</span>; what can we say about this function? For starters, if <span class="math inline">\(n\)</span> is less than <span class="math inline">\(2\)</span>, the procedure halts almost immediately, after just a couple of steps. Therefore,</p>
  <p><span class="math display">\[T(n) \leq 2 \ \text{for}\ n \leq 1.\]</span></p>
  <p>For larger values of <span class="math inline">\(n\)</span>, there are two recursive invocations of <span class="math inline">\(\text{fib1}\)</span>, taking time <span class="math inline">\(T(n-1)\)</span> and <span class="math inline">\(T(n-2)\)</span>, respectively, plus three computer steps (checks on the value of <span class="math inline">\(n\)</span> and a final addition). Therefore,</p>
  <p><span class="math display">\[T(n) = T(n-1) + T(n-2) + 3 \ \text{for}\ n &gt; 1.\]</span></p>
  <p>Compare this to the recurrence relation for <span class="math inline">\(F_n\)</span>: we immediately see that <span class="math inline">\(T(n) \geq F_n\)</span>.</p>
  <p>This is very bad news: the running time of the algorithm grows as fast as the Fibonacci numbers! <span class="math inline">\(T(n)\)</span> is <em>exponential in</em> <span class="math inline">\(n\)</span>, which implies that the algorithm is impractically slow except for very small values of <span class="math inline">\(n\)</span>.</p>
  <p> </p>
  <div class="figure">
  <img src="fig-0.1-fibonacci-tree.png" alt="Figure 0.1 The proliferation of recursive calls in fib1." />
  <p class="caption"><strong>Figure 0.1</strong> The proliferation of recursive calls in fib1.</p>
  </div>
  <p> </p>
  <p>Let's be a little more concrete about just how bad exponential time is.</p>
  <p>To compute <span class="math inline">\(F_{200}\)</span>, the <span class="math inline">\(\text{fib1}\)</span> algorithm executes <span class="math inline">\(T(200) \geq F_{200} \geq 2^{138}\)</span> elementary computer steps. How long this actually takes depends, of course, on the computer used.</p>
  <p>At this time, the fastest computer in the world is the <a href="https://en.wikipedia.org/wiki/Earth_Simulator">NEC Earth Simulator</a>, which clocks 40 trillion steps per second. Even on this machine, <span class="math inline">\(\text{fib1}(200)\)</span> would take at least 292 seconds. This means that, if we start the computation today, it would still be going long after the sun turns into a red giant star.</p>
  <p>But technology is rapidly improving computer speeds have been doubling roughly every 18 months, a phenomenon sometimes called <em><a href="https://en.wikipedia.org/wiki/Moore%27s_law">Moore's law</a></em>. With this extraordinary growth, perhaps <span class="math inline">\(\text{fib1}\)</span> will run a lot faster on next year's machines.</p>
  <p>Let's see the running time of <span class="math inline">\(\text{fib1}(n)\)</span> is proportional to <span class="math inline">\(2^{0.694n} \approx (1.6)^{n}\)</span>, so it takes <span class="math inline">\(1.6\)</span> times longer to compute <span class="math inline">\(F_{n+1}\)</span> than <span class="math inline">\(F_{n}\)</span>. And under Moore's law, computers get roughly <span class="math inline">\(1.6\)</span> times faster each year. So if we can reasonably compute <span class="math inline">\(F_{100}\)</span> with this year's technology, then next year we will manage <span class="math inline">\(F_{101}\)</span>. And the year after, <span class="math inline">\(F_{102}\)</span>.</p>
  <p>And so on: just one more Fibonacci number every year! Such is the curse of exponential time.</p>
  <p>In short, our naive recursive algorithm is correct but hopelessly inefficient. <em>Can we do better?</em></p>
  <h3 id="a-polynomial-algorithm">A polynomial algorithm</h3>
  <p>Let's try to understand why <span class="math inline">\(\text{fib1}\)</span> is so slow. Figure 0.1 shows the cascade of recursive invocations triggered by a single call to <span class="math inline">\(\text{fib1}(n)\)</span>. Notice that many computations are repeated!</p>
  <p>A more sensible scheme would store the intermediate results—the values <span class="math inline">\(F_{0}, F_{1}, \cdots, F_{n-1}\)</span>—as soon as they become known.</p>
  <div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="kw">def</span> fib2(n):
          <span class="co"># Base case.</span>
          <span class="cf">if</span> n <span class="op">==</span> <span class="dv">0</span>:
                  <span class="cf">return</span> <span class="dv">0</span>

          <span class="co"># Initialize array.</span>
          f <span class="op">=</span> []<span class="op">;</span> f[<span class="dv">0</span>] <span class="op">=</span> <span class="dv">0</span><span class="op">;</span> f[<span class="dv">1</span>] <span class="op">=</span> <span class="dv">1</span>

          <span class="co"># Fill array with values.</span>
          <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">2</span>, n):
                  f[i] <span class="op">=</span> f[i <span class="op">-</span> <span class="dv">1</span>] <span class="op">+</span> f[i <span class="op">-</span> <span class="dv">2</span>]

          <span class="cf">return</span> f[n]</code></pre></div>
  <p>As with <span class="math inline">\(\text{fib1}\)</span>, the correctness of this algorithm is self-evident because it directly uses the definition of <span class="math inline">\(F_n\)</span>. How long does it take? The inner loop consists of a single computer step and is executed <span class="math inline">\(n - 1\)</span> times.</p>
  <p>Therefore the number of computer steps used by <span class="math inline">\(\text{fib2}\)</span> is <em>linear in</em> <span class="math inline">\(n\)</span>. From exponential we are down to polynomial, a huge breakthrough in running time. It is now perfectly reasonable to compute <span class="math inline">\(F_{200}\)</span> or even <span class="math inline">\(F_{200,000}\)</span>.<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a></p>
  <p>As we will see repeatedly throughout this book, the right algorithm makes all the difference.</p>
  <h3 id="a-more-careful-analysis">A more careful analysis</h3>
  <p>In our discussion so far, we have been counting the number of <em>basic computer steps</em> executed by each algorithm and thinking of these basic steps as taking a constant amount of time.</p>
  <p>This is a very useful simplification. After all, a processor's instruction set has a variety of basic primitives branching, storing to memory, comparing numbers, simple arithmetic, and so on and rather than distinguishing between these elementary operations, it is far more convenient to lump them together into one category.</p>
  <p>But looking back at our treatment of Fibonacci algorithms, we have been too liberal with what we consider a basic step. It is reasonable to treat addition as a single computer step if small numbers are being added, 32-bit numbers say.</p>
  <p>But the <span class="math inline">\(n\)</span>th Fibonacci number is about <span class="math inline">\(0.694n\)</span> bits long, and this can far exceed 32 as <span class="math inline">\(n\)</span> grows. Arithmetic operations on arbitrarily large numbers cannot possibly be performed in a single, constant-time step. We need to audit our earlier running time estimates and make them more honest.</p>
  <p>We will see in Chapter 1 that the addition of two n-bit numbers takes time roughly proportional to <span class="math inline">\(n\)</span>; this is not too hard to understand if you think back to the grade-school procedure for addition, which works on one digit at a time.</p>
  <p>Thus <span class="math inline">\(\text{fib1}\)</span>, which performs about <span class="math inline">\(F_{n}\)</span> additions, actually uses a number of <em>basic steps</em> roughly proportional to <span class="math inline">\(nF_{n}\)</span>. Likewise, the number of steps taken by <span class="math inline">\(\text{fib2}\)</span> is proportional to <span class="math inline">\(n^2\)</span>, still polynomial in <span class="math inline">\(n\)</span> and therefore exponentially superior to <span class="math inline">\(\text{fib1}\)</span>.</p>
  <p>This correction to the running time analysis does not diminish our breakthrough.</p>
  <p><em>But can we do even better than <span class="math inline">\(\text{fib2}\)</span>?</em> Indeed we can: see Exercise 0.4.</p>
  <p> </p>
  <div class="footnotes">
  <hr />
  <ol>
  <li id="fn1"><p>To better appreciate the importance of this dichotomy between exponential and polynomial algorithms, the reader may want to peek ahead to the <em>story of Sissa and Moore</em>, in Chapter 8.<a href="#fnref1">↩</a></p></li>
  </ol>
  </div>

  <script>
    renderMathInElement(
        document.body,
        {
            delimiters: [
                {left: "$$", right: "$$", display: true},
                {left: "\\[", right: "\\]", display: true},
                {left: "$", right: "$", display: false},
                {left: "\\(", right: "\\)", display: false}
            ]
        }
    );
  </script>
</body>

</html>
